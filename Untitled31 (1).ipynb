{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhH3nJuFir4O"
      },
      "outputs": [],
      "source": [
        "!pip install snscrape\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import datetime as dt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ngHl9XSmcrg"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLFVDeERkIaS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import bs4\n",
        "import textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "CimnhDEBl7jZ",
        "outputId": "2f57de4d-eac5-440a-b4ca-947be671f52b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-632de65b-fb5f-4a4f-8f48-d9b409e94394\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@Roblox_RTC we want him back</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@worldinpetals Can’t believe @tobyfox STOLE ph...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>can't y'all just let us be happy and enjoy 2...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F4 Thailand is so promising waaah my heart  ((...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@favstoubia I felt terrible for her   If I was...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>@trinhers my #NewYearsResolutions is to be unb...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>@sabina she's in a better place now, i feel so...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>@Estadistafiscal i buy jose cuervo bc its chea...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>@lordsociety_nft I was removed from the discor...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>@cor__dero not the dad dying</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-632de65b-fb5f-4a4f-8f48-d9b409e94394')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-632de65b-fb5f-4a4f-8f48-d9b409e94394 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-632de65b-fb5f-4a4f-8f48-d9b409e94394');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15ba8570-ae19-4f80-80fa-4c20bde417d4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15ba8570-ae19-4f80-80fa-4c20bde417d4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15ba8570-ae19-4f80-80fa-4c20bde417d4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                tweet sentiment\n",
              "0                      @Roblox_RTC we want him back    Negative\n",
              "1   @worldinpetals Can’t believe @tobyfox STOLE ph...  Negative\n",
              "2     can't y'all just let us be happy and enjoy 2...  Negative\n",
              "3   F4 Thailand is so promising waaah my heart  ((...  Negative\n",
              "4   @favstoubia I felt terrible for her   If I was...  Negative\n",
              "..                                                ...       ...\n",
              "95  @trinhers my #NewYearsResolutions is to be unb...  Negative\n",
              "96  @sabina she's in a better place now, i feel so...  Negative\n",
              "97  @Estadistafiscal i buy jose cuervo bc its chea...  Negative\n",
              "98  @lordsociety_nft I was removed from the discor...  Negative\n",
              "99                     @cor__dero not the dad dying    Negative\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# URL of the CSV file\n",
        "url = 'https://raw.githubusercontent.com/tmtsmrsl/TwitterSentimentAnalyzer/main/dataset/labeled_tweets.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Display the DataFrame\n",
        "df = df.drop(columns=[\"username\", \"date\"])\n",
        "df.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj9CWLgtmF_z"
      },
      "outputs": [],
      "source": [
        "from nltk import pos_tag\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxWpePRr3Lqj",
        "outputId": "81a8c09a-081c-4e4d-df6b-711709c6d92c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                    tweet sentiment  \\\n",
            "0                          @Roblox_RTC we want him back    Negative   \n",
            "1       @worldinpetals Can’t believe @tobyfox STOLE ph...  Negative   \n",
            "2         can't y'all just let us be happy and enjoy 2...  Negative   \n",
            "3       F4 Thailand is so promising waaah my heart  ((...  Negative   \n",
            "4       @favstoubia I felt terrible for her   If I was...  Negative   \n",
            "...                                                   ...       ...   \n",
            "702096  @Mary_Walton i use horse bedding for my boys! ...  Positive   \n",
            "702097  @cwilhelm_ Yeah, that's interesting how he arg...  Positive   \n",
            "702098        Absolutely tf not   https://t.co/i6kEbyhXQp  Positive   \n",
            "702099  @Cillaron500 @Michael951413 That’s in my profi...  Positive   \n",
            "702100       foo   : 580ded37-9c83-4349-8e6b-7224bf341d0a  Positive   \n",
            "\n",
            "                                            cleaned_tweet  \n",
            "0                                               want back  \n",
            "1                       cant believ stole phone call fnaf  \n",
            "2       cant yall let us happi enjoy fave meet kind do...  \n",
            "3       f thailand promis waaah heart thyme domyouji r...  \n",
            "4                                    felt terribl id piss  \n",
            "...                                                   ...  \n",
            "702096  use hors bed boy lot cheaper better environ al...  \n",
            "702097  yeah that interest argu pov deriv smoothlychan...  \n",
            "702098                                         absolut tf  \n",
            "702099                                        that profil  \n",
            "702100                                     foo dedcebbfda  \n",
            "\n",
            "[702101 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "\n",
        "\n",
        "# Function to clean and preprocess tweets\n",
        "def preprocess_tweet(tweet):\n",
        "    # Remove special characters, URLs, and user mentions\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|@[^\\s]+', '', tweet)\n",
        "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    # Tokenize words\n",
        "    words = word_tokenize(tweet)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    # Join the cleaned words\n",
        "    cleaned_tweet = ' '.join(words)\n",
        "\n",
        "    return cleaned_tweet\n",
        "\n",
        "# Apply the preprocessing function to the 'tweet' column and create a new 'cleaned_tweet' column\n",
        "df['cleaned_tweet'] = df['tweet'].apply(preprocess_tweet)\n",
        "\n",
        "# Display all three attributes\n",
        "print(df[['tweet', 'sentiment', 'cleaned_tweet']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_iuJJyrJvqg"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "df = df[df[\"cleaned_tweet\"].notna() & (df[\"cleaned_tweet\"] != \"\")]\n",
        "\n",
        "train_df = df.sample(frac=0.8, random_state=42)\n",
        "test_df = df.drop(index=train_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weJuAZWJNSE1"
      },
      "outputs": [],
      "source": [
        "X = train_df.cleaned_tweet\n",
        "y = train_df.sentiment\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, train_size=0.8, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIDMHgezNzXM",
        "outputId": "ae86d2ff-0fd8-4462-d79f-37595e4f6410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Unique Words: 111493\n",
            "Tokenizer saved to: tokenizer.pickle\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import pickle\n",
        "\n",
        "# Assuming X_train is your training data containing text\n",
        "\n",
        "# Create Tokenizer and fit on training data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Get vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Number of Unique Words: {}\".format(vocab_size))\n",
        "\n",
        "# Save tokenizer to a local file\n",
        "tokenizer_file_path = \"tokenizer.pickle\"\n",
        "with open(tokenizer_file_path, \"wb\") as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(f\"Tokenizer saved to: {tokenizer_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuFjnDRxN9oP"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train))\n",
        "input_len = X_train.shape[1]\n",
        "X_val = pad_sequences(tokenizer.texts_to_sequences(X_val), maxlen=input_len)\n",
        "y_train = y_train.replace({\"Negative\": 0, \"Positive\": 1})\n",
        "y_val = y_val.replace({\"Negative\": 0, \"Positive\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdDi3K9OOJvR",
        "outputId": "7c15794b-b9b9-485d-a424-4027d94ef7f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-20 12:34:46--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2023-12-20 12:34:46--  https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  5.00MB/s    in 4m 44s  \n",
            "\n",
            "2023-12-20 12:39:31 (5.10 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  /content/glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# download the pre-trained GloVe embedding (27B tokens based on 2B tweets)\n",
        "file_url = \"https://nlp.stanford.edu/data/glove.twitter.27B.zip\"\n",
        "!wget $file_url\n",
        "!unzip /content/glove.twitter.27B.zip\n",
        "\n",
        "# load the pre-trained GloVe embedding with 200 dimensions into a dictionary\n",
        "embeddings_index = {}\n",
        "with open(\"/content/glove.twitter.27B.200d.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "# create our embedding matrix\n",
        "embed_dim = 200\n",
        "embedding_matrix = np.zeros((vocab_size, embed_dim))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if word in embeddings_index:\n",
        "        embedding_matrix[index] = embeddings_index[word]\n",
        "\n",
        "# create the embedding layer\n",
        "embedding_layer = Embedding(input_dim=vocab_size,\n",
        "                            output_dim=embed_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=input_len,\n",
        "                            trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV1hrB0UP0iN",
        "outputId": "33124e52-0340-41e1-a290-36c640e9df9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 54, 200)           22298600  \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 54, 200)           0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 150)               210600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 151       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22509351 (85.87 MB)\n",
            "Trainable params: 210751 (823.25 KB)\n",
            "Non-trainable params: 22298600 (85.06 MB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(150, dropout=0.25, recurrent_dropout=0.25))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ-n_fgKQZnL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define callbacks\n",
        "es_callback = EarlyStopping(monitor=\"val_loss\", patience=3)\n",
        "mc_callback = ModelCheckpoint(\n",
        "    filepath=\"lstm_model-{epoch:02d}.h5\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[es_callback, mc_callback],\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "# The best model will be saved locally with the specified format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8rVji7MGAQB",
        "outputId": "cee5036a-133c-4abb-efa6-eecd9383d38a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4339/4339 [==============================] - 163s 37ms/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "model = load_model(\"/content/lstm_model-08.h5\")\n",
        "sequences = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(test_df[\"cleaned_tweet\"]), maxlen=input_len\n",
        ")\n",
        "test_df[\"score\"] = model.predict(sequences)\n",
        "test_df[\"pred_sentiment\"] = test_df[\"score\"].apply(\n",
        "    lambda x: \"Positive\" if x >= 0.50 else \"Negative\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P5xc3ZFH0Ex",
        "outputId": "f1f269e7-d38c-4183-ed77-9a7eb5ae51d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7781370861451814"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(test_df[\"sentiment\"], test_df[\"pred_sentiment\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-CTHC5iH4Fi",
        "outputId": "3fd7c888-a466-450c-e09e-483fe5342682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Negative Rate: 0.799\n",
            "True Positive Rate: 0.757\n"
          ]
        }
      ],
      "source": [
        "tn, fp, fn, tp = confusion_matrix(\n",
        "    test_df[\"sentiment\"], test_df[\"pred_sentiment\"]\n",
        ").ravel()\n",
        "tnr = tn / (tn + fp)\n",
        "tpr = tp / (tp + fn)\n",
        "print(\"True Negative Rate: {:.3f}\".format(tnr))\n",
        "print(\"True Positive Rate: {:.3f}\".format(tpr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXuoLT_KJWWi",
        "outputId": "c6c7a539-150f-4a04-b0a5-d7f718bbbd74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# for scraping tweets\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "\n",
        "# for loading the model and tokenizer\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# for text processing\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "nltk.download(\n",
        "    [\"punkt\", \"wordnet\", \"omw-1.4\", \"averaged_perceptron_tagger\", \"universal_tagset\"]\n",
        ")\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# for visualization\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuGKrDSK6JP8"
      },
      "outputs": [],
      "source": [
        "def get_latest_tweet_df(search_term, num_tweets):\n",
        "    tweet_data = []\n",
        "    # only scrape tweets in English\n",
        "    for i, tweet in enumerate(\n",
        "        sntwitter.TwitterSearchScraper(\"{} lang:en\".format(search_term)).get_items()\n",
        "    ):\n",
        "        # the number of tweets scraped are limited to 5000\n",
        "        if i >= num_tweets or i >= 5000:\n",
        "            break\n",
        "        tweet_data.append(\n",
        "            [tweet.user.username, tweet.date, tweet.likeCount, tweet.content]\n",
        "        )\n",
        "\n",
        "    tweet_df = pd.DataFrame(\n",
        "        tweet_data, columns=[\"Username\", \"Date\", \"Like Count\", \"Tweet\"]\n",
        "    )\n",
        "    return tweet_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUZIBByW6MKF"
      },
      "outputs": [],
      "source": [
        "def text_preprocessing(text):\n",
        "    # load the stopwords and lemmatizer\n",
        "    stopwords = set()\n",
        "    with open(\"static/en_stopwords.txt\", \"r\") as file:\n",
        "        for word in file:\n",
        "            stopwords.add(word.rstrip(\"\\n\"))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    try:\n",
        "        url_pattern = r\"((http://)[^ ]*|(https://)[^ ]*|(www\\.)[^ ]*)\"\n",
        "        user_pattern = r\"@[^\\s]+\"\n",
        "        entity_pattern = r\"&.*;\"\n",
        "        neg_contraction = r\"n't\\W\"\n",
        "        non_alpha = \"[^a-z]\"\n",
        "        cleaned_text = text.lower()\n",
        "        cleaned_text = re.sub(neg_contraction, \" not \", cleaned_text)\n",
        "        cleaned_text = re.sub(url_pattern, \" \", cleaned_text)\n",
        "        cleaned_text = re.sub(user_pattern, \" \", cleaned_text)\n",
        "        cleaned_text = re.sub(entity_pattern, \" \", cleaned_text)\n",
        "        cleaned_text = re.sub(non_alpha, \" \", cleaned_text)\n",
        "        tokens = word_tokenize(cleaned_text)\n",
        "        # provide POS tag for lemmatization to yield better result\n",
        "        word_tag_tuples = pos_tag(tokens, tagset=\"universal\")\n",
        "        tag_dict = {\"NOUN\": \"n\", \"VERB\": \"v\", \"ADJ\": \"a\", \"ADV\": \"r\"}\n",
        "        final_tokens = []\n",
        "        for word, tag in word_tag_tuples:\n",
        "            if len(word) > 1 and word not in stopwords:\n",
        "                if tag in tag_dict:\n",
        "                    final_tokens.append(lemmatizer.lemmatize(word, tag_dict[tag]))\n",
        "                else:\n",
        "                    final_tokens.append(lemmatizer.lemmatize(word))\n",
        "        return \" \".join(final_tokens)\n",
        "    except:\n",
        "        return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROOciltm6Owi"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(tweet_df):\n",
        "    # load the model and tokenizer\n",
        "    model = load_model(\"static/lstm_model.h5\")\n",
        "    with open(\"static/tokenizer.pickle\", \"rb\") as handle:\n",
        "        custom_tokenizer = pickle.load(handle)\n",
        "\n",
        "    # preprocess the tweets\n",
        "    temp_df = tweet_df.copy()\n",
        "    temp_df[\"Cleaned Tweet\"] = temp_df[\"Tweet\"].apply(text_preprocessing)\n",
        "    temp_df = temp_df[temp_df[\"Cleaned Tweet\"].notna() & temp_df[\"Cleaned Tweet\"] != \"\"]\n",
        "\n",
        "    # tokenize the tweets then pad the sequences (54 is the maxlen of the training data)\n",
        "    sequences = pad_sequences(\n",
        "        custom_tokenizer.texts_to_sequences(temp_df[\"Cleaned Tweet\"]), maxlen=54\n",
        "    )\n",
        "\n",
        "    # predict the sentiment by setting the probability threshold to 0.50\n",
        "    score = model.predict(sequences)\n",
        "    temp_df[\"Score\"] = score\n",
        "    temp_df[\"Sentiment\"] = temp_df[\"Score\"].apply(\n",
        "        lambda x: \"Positive\" if x >= 0.50 else \"Negative\"\n",
        "    )\n",
        "    return temp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8qdJORR6RLE"
      },
      "outputs": [],
      "source": [
        "def plot_sentiment(tweet_df):\n",
        "    # count the number tweets based on the sentiment\n",
        "    sentiment_count = tweet_df[\"Sentiment\"].value_counts()\n",
        "\n",
        "    # plot the sentiment distribution in a pie chart\n",
        "    fig = px.pie(\n",
        "        values=sentiment_count.values,\n",
        "        names=sentiment_count.index,\n",
        "        hole=0.3,\n",
        "        title=\"<b>Sentiment Distribution</b>\",\n",
        "        color=sentiment_count.index,\n",
        "        # set the color of positive to blue and negative to orange\n",
        "        color_discrete_map={\"Positive\": \"#1F77B4\", \"Negative\": \"#FF7F0E\"},\n",
        "    )\n",
        "    fig.update_traces(\n",
        "        textposition=\"inside\",\n",
        "        texttemplate=\"%{label}<br>%{value} (%{percent})\",\n",
        "        hovertemplate=\"<b>%{label}</b><br>Percentage=%{percent}<br>Count=%{value}\",\n",
        "    )\n",
        "    fig.update_layout(showlegend=False)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axj3WPIN6UaU"
      },
      "outputs": [],
      "source": [
        "def plot_wordcloud(tweet_df, colormap=\"Greens\"):\n",
        "    # load the stopwords\n",
        "    stopwords = set()\n",
        "    with open(\"static/en_stopwords_viz.txt\", \"r\") as file:\n",
        "        for word in file:\n",
        "            stopwords.add(word.rstrip(\"\\n\"))\n",
        "\n",
        "    # load the mask image and font type\n",
        "    mask = np.array(Image.open(\"static/twitter_mask.png\"))\n",
        "    font = \"static/quartzo.ttf\"\n",
        "\n",
        "    # generate custom colormap\n",
        "    cmap = mpl.cm.get_cmap(colormap)(np.linspace(0, 1, 20))\n",
        "    cmap = mpl.colors.ListedColormap(cmap[10:15])\n",
        "\n",
        "    # combine all the preprocessed tweets into a single string\n",
        "    text = \" \".join(tweet_df[\"Cleaned Tweet\"])\n",
        "\n",
        "    # create the WordCloud instance\n",
        "    wc = WordCloud(\n",
        "        background_color=\"white\",\n",
        "        font_path=font,\n",
        "        stopwords=stopwords,\n",
        "        max_words=90,\n",
        "        colormap=cmap,\n",
        "        mask=mask,\n",
        "        random_state=42,\n",
        "        collocations=False,\n",
        "        min_word_length=2,\n",
        "        max_font_size=200,\n",
        "    )\n",
        "\n",
        "    # generate and plot the wordcloud\n",
        "    wc.generate(text)\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    plt.imshow(wc, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Wordcloud\", fontdict={\"fontsize\": 16}, fontweight=\"heavy\", pad=20, y=1.0)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcXlT--s6X8e"
      },
      "outputs": [],
      "source": [
        "def get_top_n_gram(tweet_df, ngram_range, n=10):\n",
        "    # load the stopwords\n",
        "    stopwords = set()\n",
        "    with open(\"static/en_stopwords_viz.txt\", \"r\") as file:\n",
        "        for word in file:\n",
        "            stopwords.add(word.rstrip(\"\\n\"))\n",
        "\n",
        "    # load the corpus and vectorizer\n",
        "    corpus = tweet_df[\"Cleaned Tweet\"]\n",
        "    vectorizer = CountVectorizer(\n",
        "        analyzer=\"word\", ngram_range=ngram_range, stop_words=stopwords\n",
        "    )\n",
        "\n",
        "    # use the vectorizer to count the n-grams frequencies\n",
        "    X = vectorizer.fit_transform(corpus.astype(str).values)\n",
        "    words = vectorizer.get_feature_names_out()\n",
        "    words_count = np.ravel(X.sum(axis=0))\n",
        "\n",
        "    # store the results in a dataframe\n",
        "    df = pd.DataFrame(zip(words, words_count))\n",
        "    df.columns = [\"words\", \"counts\"]\n",
        "    df = df.sort_values(by=\"counts\", ascending=False).head(n)\n",
        "    df[\"words\"] = df[\"words\"].str.title()\n",
        "    return df\n",
        "\n",
        "def plot_n_gram(n_gram_df, title, color=\"#54A24B\"):\n",
        "    # plot the top n-grams frequencies in a bar chart\n",
        "    fig = px.bar(\n",
        "        x=n_gram_df.counts,\n",
        "        y=n_gram_df.words,\n",
        "        title=\"<b>{}</b>\".format(title),\n",
        "        text_auto=True,\n",
        "    )\n",
        "    fig.update_layout(plot_bgcolor=\"white\")\n",
        "    fig.update_xaxes(title=None)\n",
        "    fig.update_yaxes(autorange=\"reversed\", title=None)\n",
        "    fig.update_traces(hovertemplate=\"<b>%{y}</b><br>Count=%{x}\", marker_color=color)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1X1SSjC6ahM"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import helper_functions as hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6xnF4h06dA2"
      },
      "outputs": [],
      "source": [
        "pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJbpPHG0CGEy"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4-R9DBjCTIC",
        "outputId": "cfb2af5b-ae2e-48ec-947e-4f7cff47c244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[##................] / loadDep:strip-ansi: sill resolveWithNewModule ansi-regex\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.229.223.191:8502\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 6.728s\n",
            "your url is: https://twenty-bushes-scream.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}